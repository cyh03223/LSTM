import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras import Sequential

def make_dataset(X, Y, batch_size=1, shuffle=True):
    ds = tf.data.Dataset.from_tensor_slices((X, Y))
    if shuffle:
        ds = ds.shuffle(1024)
    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)

# Load the .npz file
data = np.load('lorenz_data.npz')  # the data file generated by ks or lorenz
X_data = data['X_data'].astype(np.float32)  # shape (num_records, seq_length, dim_x)
Y_data = data['Y_data'].astype(np.float32)  # shape (num_records, seq_length, dim_y)
data_len = 50
train_size = int(data_len * 0.8)
val_size = (data_len - train_size) // 2
test_size = data_len - train_size - val_size

X_train, Y_train = X_data[:train_size], Y_data[:train_size]
X_val,   Y_val   = X_data[train_size:train_size + val_size], Y_data[train_size:train_size + val_size]
X_test,  Y_test  = X_data[train_size + val_size:], Y_data[train_size + val_size:]
X_train_reshaped = X_train.reshape(-1,X_train.shape[2])
Y_train_reshaped = Y_train.reshape(-1,Y_train.shape[2])

mean_x = X_train_reshaped.mean(axis=0)
std_x = X_train_reshaped.std(axis=0)
mean_y = Y_train_reshaped.mean(axis=0)
std_y = Y_train_reshaped.std(axis=0)
print("mean of states is",mean_x)
print("mean of measurements is",mean_y)
print("standard deviation of states is",std_x)
print("standard deviation of measurements is",std_y)

X_train_norm = (X_train - mean_x) / std_x
Y_train_norm = (Y_train - mean_y) / std_y
X_val_norm = (X_val - mean_x) / std_x
Y_val_norm = (Y_val - mean_y) / std_y
X_test_norm = (X_test - mean_x) / std_x
Y_test_norm = (Y_test - mean_y) / std_y

batch_size = 5
train_dataset = make_dataset(X_train_norm, Y_train_norm, batch_size, shuffle=False)
val_dataset   = make_dataset(X_val_norm,   Y_val_norm,   batch_size, shuffle=False)
test_dataset  = make_dataset(X_test_norm,  Y_test_norm,  batch_size, shuffle=False)

hidden_size = 50
dim_y = 1
dim_x = 3
rnn = Sequential([
    LSTM(dim_x, return_sequences=True, input_shape=(None, dim_y)),
    # Dense(dim_x)
])
criterion = tf.keras.losses.MeanSquaredError() # Use Mean Squared Error as loss function

# Set up learning rate with factor and patience
init_lr = 1e-1
min_lr = 1e-2
min_delta = 1e-3
factor = 0.5
patience = 5
halt_patience = 10
optimizer = tf.keras.optimizers.legacy.Adam(init_lr)

# Training step implementation
@tf.function
def train_step(x_batch, y_batch):
    input_data = y_batch
    output_data = x_batch

    with tf.GradientTape() as tape:
        outputs = rnn(input_data, training=True)
        loss = criterion(output_data, outputs)

    # Backâ€‘propagate & update all trainable weights
    train_vars = rnn.trainable_variables
    grads = tape.gradient(loss, train_vars)
    optimizer.apply_gradients(zip(grads, train_vars))

    return loss

# Validation step implementation
@tf.function
def val_step(x_batch, y_batch):
    input_data = y_batch
    output_data = x_batch
    outputs = rnn(input_data, training=False)
    loss = criterion(output_data, outputs)
    return loss

# Training loop
epochs = 15000
best_val = float('inf')
halt_count = 0
wait = 0

for epoch in range(1, epochs + 1):
    # Train
    total_train_loss = 0.0
    train_steps = 0
    for x_batch, y_batch in train_dataset:
        batch_loss = train_step(x_batch, y_batch)
        total_train_loss += batch_loss
        train_steps += 1
    train_loss = total_train_loss / train_steps

    # Validate
    total_val_loss = 0.0
    val_steps = 0
    for x_batch, y_batch in val_dataset:
        v_loss = val_step(x_batch, y_batch)
        total_val_loss += v_loss
        val_steps += 1
    val_loss = total_val_loss / val_steps

    if val_loss >= best_val:
        halt_count += 1
    else:
        best_val = val_loss
        halt_count = 0

    if halt_count >= halt_patience:
        print(f"No more effective epoch at {epoch:03d}: Train MSE = {train_loss:.4f}, Val MSE = {val_loss:.4f}")
        break

    # Apply new learning rate
    if val_loss < best_val - min_delta:
        best_val = val_loss
        wait = 0
        halt_count = 0
    else:
        wait += 1
        if wait >= patience:
            # decay the LR
            new_lr = max(optimizer.learning_rate.numpy() * factor, min_lr)
            optimizer.learning_rate.assign(new_lr)
            wait = 0

    print(f"Epoch {epoch:03d}: Train MSE = {train_loss:.4f}, Val MSE = {val_loss:.4f} (LR={optimizer.learning_rate.numpy():.4f})")


# Eval loop
total_test_loss = 0.0
test_steps = 0
for x_batch, y_batch in test_dataset:
    t_loss = val_step(x_batch, y_batch)
    total_test_loss += t_loss
    test_steps += 1
print(f"Test  MSE = {total_test_loss / test_steps:.4f}")